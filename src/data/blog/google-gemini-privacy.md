---
author: Eliot Bendinelli
pubDatetime: 2025-07-09
modDatetime: 
title: Why does Google wants Gemini to access your Whatsapp messages?
slug: google-gemini-ai-assistant-privacy-risk
featured: false
draft: false
tags:
  - tech
description: Google wants it's AI assistant to be the centrepiece of your digital life, but the privacy and security cost is high
---
In the last few days, I've seen [a lot](https://www.laptopmag.com/ai/gemini-phone-access-update) [of](https://www.androidauthority.com/gemini-apps-activity-email-july-7-3570651/) [coverage](https://arstechnica.com/security/2025/07/unless-users-take-action-android-will-let-gemini-access-third-party-apps/?comments-page=1#comments) of an announcement from Google (or rather an email to its users) about a change in Gemini. The change would allegedly allow it to access third-party apps like Whatsapp, Phone and Messages by default on Android. 

I have not received said email (despite still having a Google account I monitor once in a while) but I can tell this is not really news. A couple of months ago, I tested Gemini and a few other AI chatbot apps on Android to examine how they interacted with other apps. Gemini already had this feature, and you could turn it off. 

The only change the email actually describes is that you can have Gemini access those third-party apps even with "Gemini App Activity" turned off, which wasn't possible before. A good comparison is how Youtube's homepage looks empty when you disable Youtube watch history. The recommended content feature is basically disabled if you don't let Google record your activity. Well, for Gemini it would not let you integrate with third-party apps if you didn't let Google record your Gemini activity (a.k.a.: everything you ask it).

But this doesn't really matter. The real news here is how Google is forcing integration with third-party apps to impose Gemini as the centrepiece of your digital life. To turn AI chatbot into useful assistants, tech companies need them to have access to your entire digital life, and Google is taking the bullish way to make that happen.  
  
I'm not against the idea of developing useful AI tools, even though at this stage I think the technology produces [more harm than good](/posts/why-i-would-rather-push-against-ai/), but it cannot be done at the expense of users' agency and privacy. Giving these tools access to highly sensitive data creates security and privacy risks that are not negligible. And right now, Google continues giving us more proof that we can't trust them with more access to our digital life. Because saying things like "no data is recorded but it will still be stored for 72 hours" tells me all I need to know about whether the Whatsapp messages accessed by Gemini will reach Google's server or not.
  
I've written about the [security and privacy risks of AI assistant accessing third-party apps](https://privacyinternational.org/long-read/5555/your-future-ai-assistant-still-needs-earn-your-trust) and data for Privacy International recently, and I've been keeping an eye out on their developments. News (or non-news) like this only confirms the concerned raised in that piece: we cannot trust AI developers with our security and privacy, and linking AI assistants (or AI chatbots) with third-party apps at this point in time is just massively increasing your attack surface.